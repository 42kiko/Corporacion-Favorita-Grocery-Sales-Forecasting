{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c898d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Bootstrapped project root: /Users/kiko/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 00:34:37.914 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data directory: /Users/kiko/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/data\n",
      "‚öôÔ∏è Config file:    /Users/kiko/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/configs/data/active.yaml  (exists=True)\n",
      "‚úÖ YAML path already correct.\n",
      "‚úÖ DataLoader initialisiert.\n",
      "\n",
      "üßæ Files BEFORE preprocessing:\n",
      "    holidays_events.csv\n",
      "    holidays_events_part1.parquet\n",
      "    items.csv\n",
      "    items_part1.parquet\n",
      "    oil.csv\n",
      "    oil_part1.parquet\n",
      "    sample_submission.csv\n",
      "    sample_submission_part1.parquet\n",
      "    stores.csv\n",
      "    stores_part1.parquet\n",
      "    test.csv\n",
      "    test_part1.parquet\n",
      "    train.csv\n",
      "    train_part1.parquet\n",
      "    train_part10.parquet\n",
      "    train_part11.parquet\n",
      "    train_part12.parquet\n",
      "    train_part13.parquet\n",
      "    train_part14.parquet\n",
      "    train_part15.parquet\n",
      "    train_part16.parquet\n",
      "    train_part17.parquet\n",
      "    train_part18.parquet\n",
      "    train_part19.parquet\n",
      "    train_part2.parquet\n",
      "    train_part20.parquet\n",
      "    train_part21.parquet\n",
      "    train_part3.parquet\n",
      "    train_part4.parquet\n",
      "    train_part5.parquet\n",
      "    train_part6.parquet\n",
      "    train_part7.parquet\n",
      "    train_part8.parquet\n",
      "    train_part9.parquet\n",
      "    transactions.csv\n",
      "    transactions_part1.parquet\n",
      "\n",
      "üöÄ Running preprocessing (CSV ‚Üí Parquet SPLIT/partition)‚Ä¶\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# 4) CSV ‚Üí Parquet (Split oder Partition) ausf√ºhren\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müöÄ Running preprocessing (CSV ‚Üí Parquet SPLIT/partition)‚Ä¶\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_csv_to_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Conversion complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# 5) Erzeugte Parquet-Artefakte zeigen (Parts oder Partitionen)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/src/data_loader.py:125\u001b[39m, in \u001b[36mDataLoader.preprocess_csv_to_parquet\u001b[39m\u001b[34m(self, files)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m csv_file \u001b[38;5;129;01min\u001b[39;00m candidates:\n\u001b[32m    124\u001b[39m     base_name = csv_file.stem\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[43mst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m‚û°Ô∏è Processing \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcsv_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m ‚Ä¶\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     t0 = time.time()\n\u001b[32m    128\u001b[39m     reader = pd.read_csv(csv_file, chunksize=chunksize, low_memory=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/runtime/metrics_util.py:410\u001b[39m, in \u001b[36mgather_metrics.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m         _LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[33mFailed to collect command telemetry\u001b[39m\u001b[33m\"\u001b[39m, exc_info=ex)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     result = \u001b[43mnon_optional_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RerunException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    412\u001b[39m     \u001b[38;5;66;03m# Duplicated from below, because static analysis tools get confused\u001b[39;00m\n\u001b[32m    413\u001b[39m     \u001b[38;5;66;03m# by deferring the rethrow.\u001b[39;00m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tracking_activated \u001b[38;5;129;01mand\u001b[39;00m command_telemetry:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/elements/write.py:539\u001b[39m, in \u001b[36mWriteMixin.write\u001b[39m\u001b[34m(self, unsafe_allow_html, *args, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m             backtick_wrapper = \u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m * backtick_count\n\u001b[32m    535\u001b[39m             string_buffer.append(\n\u001b[32m    536\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbacktick_wrapper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstringified_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbacktick_wrapper\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mflush_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/elements/write.py:399\u001b[39m, in \u001b[36mWriteMixin.write.<locals>.flush_buffer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    396\u001b[39m text_content = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(string_buffer)\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# The usage of empty here prevents\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# some grey out effects:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m text_container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m text_container.markdown(\n\u001b[32m    401\u001b[39m     text_content,\n\u001b[32m    402\u001b[39m     unsafe_allow_html=unsafe_allow_html,\n\u001b[32m    403\u001b[39m )\n\u001b[32m    404\u001b[39m string_buffer[:] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/runtime/metrics_util.py:410\u001b[39m, in \u001b[36mgather_metrics.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m         _LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[33mFailed to collect command telemetry\u001b[39m\u001b[33m\"\u001b[39m, exc_info=ex)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     result = \u001b[43mnon_optional_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RerunException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    412\u001b[39m     \u001b[38;5;66;03m# Duplicated from below, because static analysis tools get confused\u001b[39;00m\n\u001b[32m    413\u001b[39m     \u001b[38;5;66;03m# by deferring the rethrow.\u001b[39;00m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tracking_activated \u001b[38;5;129;01mand\u001b[39;00m command_telemetry:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/elements/empty.py:100\u001b[39m, in \u001b[36mEmptyMixin.empty\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Insert a single-element container.\u001b[39;00m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[33;03mInserts a container into your app that can be used to hold a single element.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m \n\u001b[32m     98\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m empty_proto = EmptyProto()\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_enqueue\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mempty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mempty_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/delta_generator.py:455\u001b[39m, in \u001b[36mDeltaGenerator._enqueue\u001b[39m\u001b[34m(self, delta_type, element_proto, add_rows_metadata, user_key)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StreamlitAPIException(\n\u001b[32m    449\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCalling `st.sidebar` in a function wrapped with `st.fragment` is not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupported. To write elements to the sidebar with a fragment, call your \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfragment function inside a `with st.sidebar` context manager.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m     )\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Warn if an element is being changed but the user isn't running the streamlit server.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[43m_maybe_print_use_warning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Copy the marshalled proto into the overall msg proto\u001b[39;00m\n\u001b[32m    458\u001b[39m msg = ForwardMsg_pb2.ForwardMsg()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/delta_generator.py:131\u001b[39m, in \u001b[36m_maybe_print_use_warning\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    127\u001b[39m _use_warning_has_been_displayed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    129\u001b[39m warning = cli_util.style_for_cli(\u001b[33m\"\u001b[39m\u001b[33mWarning:\u001b[39m\u001b[33m\"\u001b[39m, bold=\u001b[38;5;28;01mTrue\u001b[39;00m, fg=\u001b[33m\"\u001b[39m\u001b[33myellow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43menv_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_repl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    132\u001b[39m     logger.get_logger(\u001b[33m\"\u001b[39m\u001b[33mroot\u001b[39m\u001b[33m\"\u001b[39m).warning(\n\u001b[32m    133\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwarning\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to view a Streamlit app on a browser, use Streamlit in a file and\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  run it with the following command:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    streamlit run [FILE_NAME] [ARGUMENTS]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m     )\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runtime.exists() \u001b[38;5;129;01mand\u001b[39;00m config.get_option(\n\u001b[32m    137\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mglobal.showWarningOnDirectExecution\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/github/Corporacion-Favorita-Grocery-Sales-Forecasting/.venv/lib/python3.13/site-packages/streamlit/env_util.py:43\u001b[39m, in \u001b[36mis_repl\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return True if running in the Python REPL.\"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m root_frame = \u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[-\u001b[32m1\u001b[39m]\n\u001b[32m     44\u001b[39m filename = root_frame[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# 1 is the filename field in this tuple.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename.endswith(os.path.join(\u001b[33m\"\u001b[39m\u001b[33mbin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mipython\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/inspect.py:1754\u001b[39m, in \u001b[36mstack\u001b[39m\u001b[34m(context)\u001b[39m\n\u001b[32m   1752\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstack\u001b[39m(context=\u001b[32m1\u001b[39m):\n\u001b[32m   1753\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetouterframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/inspect.py:1729\u001b[39m, in \u001b[36mgetouterframes\u001b[39m\u001b[34m(frame, context)\u001b[39m\n\u001b[32m   1727\u001b[39m framelist = []\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m frame:\n\u001b[32m-> \u001b[39m\u001b[32m1729\u001b[39m     traceback_info = \u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m     frameinfo = (frame,) + traceback_info\n\u001b[32m   1731\u001b[39m     framelist.append(FrameInfo(*frameinfo, positions=traceback_info.positions))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/inspect.py:1691\u001b[39m, in \u001b[36mgetframeinfo\u001b[39m\u001b[34m(frame, context)\u001b[39m\n\u001b[32m   1689\u001b[39m start = lineno - \u001b[32m1\u001b[39m - context//\u001b[32m2\u001b[39m\n\u001b[32m   1690\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1691\u001b[39m     lines, lnum = \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1693\u001b[39m     lines = index = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/inspect.py:1072\u001b[39m, in \u001b[36mfindsource\u001b[39m\u001b[34m(object)\u001b[39m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m (file.startswith(\u001b[33m'\u001b[39m\u001b[33m<\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file.endswith(\u001b[33m'\u001b[39m\u001b[33m>\u001b[39m\u001b[33m'\u001b[39m))) \u001b[38;5;129;01mor\u001b[39;00m file.endswith(\u001b[33m'\u001b[39m\u001b[33m.fwork\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33msource code not available\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m module = \u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module:\n\u001b[32m   1074\u001b[39m     lines = linecache.getlines(file, module.\u001b[34m__dict__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/inspect.py:1029\u001b[39m, in \u001b[36mgetmodule\u001b[39m\u001b[34m(object, _filename)\u001b[39m\n\u001b[32m   1026\u001b[39m         f = getabsfile(module)\n\u001b[32m   1027\u001b[39m         \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n\u001b[32m   1028\u001b[39m         modulesbyfile[f] = modulesbyfile[\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m             \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m] = module.\u001b[34m__name__\u001b[39m\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m modulesbyfile:\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sys.modules.get(modulesbyfile[file])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen posixpath>:454\u001b[39m, in \u001b[36mrealpath\u001b[39m\u001b[34m(filename, strict)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# üìò 01_data_init.ipynb  (PyYAML version)\n",
    "# Initial data preparation & verification\n",
    "# - CSV ‚Üí Parquet (Split-Parts oder partitioniert)\n",
    "# - Repariert YAML source.local_dir automatisch\n",
    "# ==============================================================\n",
    "\n",
    "# 0) Bootstrap project root (robust aus notebooks/ oder repo-root)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_CANDIDATE = Path().resolve()\n",
    "PROJECT_ROOT = ROOT_CANDIDATE.parent if ROOT_CANDIDATE.name == \"notebooks\" else ROOT_CANDIDATE\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"üì¶ Bootstrapped project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# 1) Imports & Theme\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import yaml  # <-- PyYAML statt ruamel.yaml\n",
    "\n",
    "from src.data_loader import DataLoader, ensure_dir\n",
    "\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "pio.defaults.default_width  = 900\n",
    "pio.defaults.default_height = 500\n",
    "pio.defaults.default_scale  = 2\n",
    "\n",
    "DATA_DIR    = PROJECT_ROOT / \"data\"\n",
    "CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"data\" / \"active.yaml\"\n",
    "\n",
    "ensure_dir(DATA_DIR)\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"‚öôÔ∏è Config file:    {CONFIG_PATH}  (exists={CONFIG_PATH.exists()})\")\n",
    "\n",
    "# 2) YAML source.local_dir automatisch korrigieren (PyYAML)\n",
    "if not CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Config file not found: {CONFIG_PATH}\")\n",
    "\n",
    "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f) or {}\n",
    "\n",
    "cfg.setdefault(\"source\", {})\n",
    "correct_path = str(DATA_DIR)\n",
    "\n",
    "if str(cfg[\"source\"].get(\"local_dir\")) != correct_path:\n",
    "    cfg[\"source\"][\"local_dir\"] = correct_path\n",
    "    with open(CONFIG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        # sort_keys=False, damit die Reihenfolge in etwa erhalten bleibt\n",
    "        yaml.safe_dump(cfg, f, sort_keys=False, allow_unicode=True)\n",
    "    print(f\"üõ†Ô∏è YAML updated: source.local_dir = {correct_path}\")\n",
    "else:\n",
    "    print(\"‚úÖ YAML path already correct.\")\n",
    "\n",
    "# 3) DataLoader initialisieren\n",
    "loader = DataLoader(config_path=CONFIG_PATH)\n",
    "print(\"‚úÖ DataLoader initialisiert.\")\n",
    "\n",
    "# Optional: Dateien vor dem Preprocessing listen\n",
    "print(\"\\nüßæ Files BEFORE preprocessing:\")\n",
    "for f in sorted(DATA_DIR.glob(\"*\")):\n",
    "    print(\"   \", f.name)\n",
    "\n",
    "# 4) CSV ‚Üí Parquet (Split oder Partition) ausf√ºhren\n",
    "print(\"\\nüöÄ Running preprocessing (CSV ‚Üí Parquet SPLIT/partition)‚Ä¶\")\n",
    "loader.preprocess_csv_to_parquet()\n",
    "print(\"‚úÖ Conversion complete.\")\n",
    "\n",
    "# 5) Erzeugte Parquet-Artefakte zeigen (Parts oder Partitionen)\n",
    "print(\"\\nüì¶ Generated Parquet files or folders:\")\n",
    "parquets    = sorted(DATA_DIR.glob(\"*.parquet\"))\n",
    "part_files  = sorted(DATA_DIR.glob(\"train_part*.parquet\"))\n",
    "partitions  = sorted(DATA_DIR.glob(\"train/**/*.parquet\"))\n",
    "\n",
    "if parquets:\n",
    "    for f in parquets:\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f\"   {f.name:<40} {size_mb:>8.1f} MB\")\n",
    "elif part_files:\n",
    "    for f in part_files:\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f\"   {f.name:<40} {size_mb:>8.1f} MB\")\n",
    "elif partitions:\n",
    "    for f in partitions:\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f\"   {f.relative_to(DATA_DIR):<40} {size_mb:>8.1f} MB\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è No Parquet files found. Check preprocessing configuration.\")\n",
    "\n",
    "# Hinweis, falls noch monolithisches train.parquet existiert\n",
    "mono_train = DATA_DIR / \"train.parquet\"\n",
    "if mono_train.exists():\n",
    "    print(\"\\n‚ö†Ô∏è NOTE: Found monolithic 'train.parquet'.\")\n",
    "    print(\"   Deine Config zielt auf SPLIT/Partition. L√∂sche 'train.parquet' einmalig und preprocess erneut,\")\n",
    "    print(\"   wenn du nur train_part*.parquet bzw. partitionierte Ordner willst.\")\n",
    "\n",
    "# 6) Train laden (Parts oder Partition), nur zur Sichtpr√ºfung\n",
    "def _collect_train_paths() -> list[Path]:\n",
    "    paths = sorted(DATA_DIR.glob(\"train_part*.parquet\"))\n",
    "    if not paths:\n",
    "        paths = sorted(DATA_DIR.glob(\"train/**/*.parquet\"))\n",
    "    if not paths and (DATA_DIR / \"train.parquet\").exists():\n",
    "        paths = [DATA_DIR / \"train.parquet\"]\n",
    "    return paths\n",
    "\n",
    "train_paths = _collect_train_paths()\n",
    "\n",
    "if train_paths:\n",
    "    label = \"parts\" if any(p.name.startswith(\"train_part\") for p in train_paths) else \"partitions/mono\"\n",
    "    print(f\"\\nüîó Found {len(train_paths)} train {label} ‚Üí concatenating preview ‚Ä¶\")\n",
    "    df_train = pd.concat([pd.read_parquet(p) for p in train_paths], ignore_index=True)\n",
    "    print(f\"‚úÖ Combined train: {len(df_train):,} rows √ó {len(df_train.columns)} columns\")\n",
    "\n",
    "    display(df_train.head(10))\n",
    "\n",
    "    if \"date\" in df_train.columns:\n",
    "        print(f\"üìÖ Date range: {df_train['date'].min()} ‚Üí {df_train['date'].max()}\")\n",
    "\n",
    "    na_counts = df_train.isna().sum()\n",
    "    if na_counts.any():\n",
    "        print(\"\\nüï≥Ô∏è Missing values per column (non-zero):\")\n",
    "        print(na_counts[na_counts > 0].sort_values(ascending=False))\n",
    "\n",
    "    if \"unit_sales\" in df_train.columns:\n",
    "        fig = px.histogram(df_train, x=\"unit_sales\", nbins=60,\n",
    "                           title=\"Unit Sales Distribution (combined train)\")\n",
    "        fig.show()\n",
    "\n",
    "    # Dedup-Check nach Key-Kombination\n",
    "    key_cols = [c for c in [\"id\", \"date\", \"store_nbr\"] if c in df_train.columns]\n",
    "    if key_cols:\n",
    "        dup_cnt = df_train.duplicated(subset=key_cols).sum()\n",
    "        print(f\"\\nüßπ Dedup Check on {key_cols}: duplicates = {dup_cnt:,}\")\n",
    "        if dup_cnt == 0:\n",
    "            print(\"‚úÖ No duplicate (id, date, store_nbr) combinations.\")\n",
    "        else:\n",
    "            print(\"‚ùóDuplicates detected ‚Äî pr√ºfe preprocess.deduplicate/_global.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No train parts found. Pr√ºfe YAML (preprocess.partition_by / part_size_rows).\")\n",
    "\n",
    "# 7) Meta-Datasets kurz pr√ºfen\n",
    "for name in [\"stores\", \"items\", \"oil\", \"holidays_events\", \"transactions\", \"test\", \"sample_submission\"]:\n",
    "    f = DATA_DIR / f\"{name}.parquet\"\n",
    "    if f.exists():\n",
    "        df_meta = pd.read_parquet(f)\n",
    "        print(f\"\\nüìÑ {name}.parquet ‚Üí {len(df_meta):,} rows √ó {len(df_meta.columns)} cols\")\n",
    "        display(df_meta.head())\n",
    "\n",
    "# 8) Summary\n",
    "print(\"\\nüéØ Data initialization complete!\")\n",
    "print(\"Next: open `02_eda_overview.ipynb` oder nutze `DataLoader().load_train_data()` im Code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
